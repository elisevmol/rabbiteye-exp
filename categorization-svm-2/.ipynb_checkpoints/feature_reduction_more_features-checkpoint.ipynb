{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation on new data with Bubble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import csv\n",
    "import time\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from featurize_more_features import tokenize_all\n",
    "from tqdm import tqdm_notebook\n",
    "from unidecode import unidecode\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from scipy.interpolate import spline\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.cross_validation import LeaveOneLabelOut\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#source = 'data/product_nuts_with_usage_and_product_id.csv'\n",
    "source = '/Users/elise/Documents/?/? data/new/product_nuts_with_usage_and_product_id.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_pn_usage = []\n",
    "\n",
    "with open(source) as csvfile:\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    for row in tqdm_notebook(readCSV):\n",
    "        data_pn_usage.append(eval(row[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/unidecode/__init__.py:46: RuntimeWarning: Argument <type 'str'> is not an unicode object. Passing an encoded string will likely have unexpected results.\n",
      "  _warn_if_not_unicode(string)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "id_tokens = tokenize_all(data_pn_usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove doubles\n",
    "- Include only those nut products if the usage appears in at least 3 products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# removes doubles\n",
    "known = set()\n",
    "no_doubles = []\n",
    "\n",
    "for d in tqdm_notebook(id_tokens):\n",
    "    tok = ' '.join(d['tokens'])\n",
    "    if tok in known: \n",
    "        continue\n",
    "    no_doubles.append(d)\n",
    "    known.add(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# makes a dict where each tuple has one usage and all the product_ids linked to it\n",
    "k = [{x['usage']: x['product_id']} for x in no_doubles]\n",
    "dd = defaultdict(list)\n",
    "\n",
    "for d in tqdm_notebook(k): \n",
    "    for key, value in d.iteritems():\n",
    "        dd[key].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checks if a usage is linked to at least 3 products\n",
    "allowed_usage = []\n",
    "for x in tqdm_notebook(dd.items()):\n",
    "    if len(set(x[1])) > 2:\n",
    "        allowed_usage.append(x[0])\n",
    "        \n",
    "set_allowed_usage = set(allowed_usage)\n",
    "\n",
    "complete = []\n",
    "for x in tqdm_notebook(no_doubles):\n",
    "    if x['usage'] in set_allowed_usage:\n",
    "        complete.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = [x['product_id'] for x in complete]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "K_fold = int(len(set(labels)) / 6)\n",
    "\n",
    "one = set(list(set(labels))[:K_fold])\n",
    "two = set(list(set(labels))[K_fold:(K_fold * 2)])\n",
    "three = set(list(set(labels))[(2 * K_fold):(K_fold * 3)])\n",
    "four = set(list(set(labels))[(3 * K_fold):(K_fold * 4)])\n",
    "five = set(list(set(labels))[(4 * K_fold):(K_fold * 5)])\n",
    "six = set(list(set(labels))[(5 * K_fold):])\n",
    "\n",
    "labels_6 = []\n",
    "for label in tqdm_notebook(labels):\n",
    "    if label in one:\n",
    "        labels_6.append(1)\n",
    "    elif label in two:\n",
    "        labels_6.append(2)\n",
    "    elif label in three:\n",
    "        labels_6.append(3)\n",
    "    elif label in four:\n",
    "        labels_6.append(4)\n",
    "    elif label in five:\n",
    "        labels_6.append(5)\n",
    "    elif label in six:\n",
    "        labels_6.append(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_per_item_pn_TRAIN = [' '.join(tokens['tokens']) for tokens in complete if tokens['product_id'] not in six]\n",
    "text_per_item_pn_VALIDATE = [' '.join(tokens['tokens']) for tokens in complete if tokens['product_id'] in six]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=1, binary=True)\n",
    "X_TRAIN = vectorizer.fit_transform(text_per_item_pn_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = vectorizer.vocabulary_\n",
    "vectorizer = CountVectorizer(min_df=1, vocabulary=vocab)\n",
    "X_VALIDATE = vectorizer.fit_transform(text_per_item_pn_VALIDATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_TRAIN = [x['usage'] for x in complete if x['product_id'] not in six]\n",
    "Y_VALIDATE = [x['usage'] for x in complete if x['product_id'] in six]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels_TRAIN = []\n",
    "for x in enumerate(labels_6):\n",
    "    if x[1] != 6:\n",
    "        labels_TRAIN.append(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  (21231, 39417) Y:  21231\n",
      "X:  (121662, 39417) Y:  121662 Labels:  121662\n"
     ]
    }
   ],
   "source": [
    "print 'X: ', X_VALIDATE.shape, 'Y: ', len(Y_VALIDATE)\n",
    "print 'X: ', X_TRAIN.shape, 'Y: ',len(Y_TRAIN), 'Labels: ', len(labels_TRAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Indicate Accuracy **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_scores(X, Y, labels):\n",
    "    cv = LeaveOneLabelOut(labels_TRAIN)\n",
    "    clf = LinearSVC(random_state = 2, verbose = 1, max_iter=200000)\n",
    "    scores = cross_val_score(clf, X, Y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Linear SVC 100: 0.63 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "scores = compute_scores(X_TRAIN, Y_TRAIN, labels_TRAIN)\n",
    "print \"Accuracy Linear SVC 100: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Feature Reduction **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN = []\n",
    "\n",
    "percentages = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "for precentage in percentages:\n",
    "    TRAIN.append([precentage, SelectPercentile(percentile=precentage).fit_transform(X_TRAIN, Y_TRAIN)])\n",
    "    \n",
    "# TRAIN_chi2 = []\n",
    "# percentages = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "\n",
    "# for precentage in percentages:\n",
    "#     TRAIN_chi2.append([precentage, SelectPercentile(score_func=chi2, percentile=precentage).fit_transform(X_TRAIN, Y_TRAIN)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to be implemented in the range where the accuracy drops\n",
    "TRAIN_SPECIFIC = []\n",
    "\n",
    "percentages = [71, 72, 73, 74, 75, 76, 77, 78, 79]\n",
    "for precentage in percentages:\n",
    "    TRAIN_SPECIFIC.append([precentage, SelectPercentile(percentile=precentage).fit_transform(X_TRAIN, Y_TRAIN)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Find corresponding Accuracy **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = [[train_x[0], compute_scores(train_x[1], Y_TRAIN, labels_TRAIN)] for train_x in TRAIN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_specific = [[train_x[0], compute_scores(train_x[1], Y_TRAIN, labels_TRAIN)] for train_x in TRAIN_SPECIFIC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for score in scores:\n",
    "    print \"Accuracy Linear SVC \" + str(score[0]) + \": %0.2f (+/- %0.2f)\" % (score[1].mean(), score[1].std() * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for score in scores_specific:\n",
    "    print \"Accuracy Linear SVC \" + str(score[0]) + \": %0.2f (+/- %0.2f)\" % (score[1].mean(), score[1].std() * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Plotting Accuracy against Feature Reduction **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_all = scores_specific + scores\n",
    "scores_all = [[score[0], score[1].mean()] for score in scores_all]\n",
    "scores_all.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.title('Feature Reduction')\n",
    "plt.xlabel('Percentage of the Features')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.52, 0.65])\n",
    "plt.grid(True)\n",
    "\n",
    "x = np.array([score[0] for score in scores_all])\n",
    "y = np.array([score[1] for score in scores_all])\n",
    "\n",
    "plt.plot(x, y, color='black', marker='o', linestyle='-', markerfacecolor='pink', markersize=5)\n",
    "plt.savefig('feature_reduction.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** GridSearch **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'C':[0.01, 0.1, 1, 10, 100]} \n",
    "\n",
    "svr = LinearSVC(random_state = 2, verbose = 1)\n",
    "cv = LeaveOneLabelOut(labels_TRAIN)\n",
    "X = TRAIN_SPECIFIC[5][1]\n",
    "\n",
    "clf = GridSearchCV(svr, parameters, cv=cv, scoring='accuracy')\n",
    "clf.fit(X, Y_TRAIN)\n",
    "\n",
    "print(\"Best parameters set found on development set: \\n\")\n",
    "print(clf.best_params_)\n",
    "\n",
    "grid_scores = []\n",
    "means = [y[1] for y in clf.grid_scores_]\n",
    "stds = [np.std(y[2]) for y in clf.grid_scores_]\n",
    "params = [a[0] for a in clf.grid_scores_]\n",
    "\n",
    "for mean, std, params in zip(means, stds, params):\n",
    "    grid_scores.append(\"%0.2f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "    \n",
    "grid_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "co = [(float(grid.split(':')[-1][:-1].strip()),float(grid.split(' ')[0].strip())) for grid in grid_scores]\n",
    "co.sort()\n",
    "co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = [i[0] for i in co]\n",
    "y = [i[1] for i in co]\n",
    "\n",
    "plt.plot(x, y, 'm-', marker='o')\n",
    "plt.grid(True)\n",
    "plt.ylim([0.4, 0.7])\n",
    "plt.xlim([0, 1])\n",
    "plt.title('GridSearch on C value')\n",
    "plt.xlabel('Value of C')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Validate **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform validation set to only contain selected features\n",
    "selected_percentile = # add in the selected percentile based on feature reduction\n",
    "\n",
    "selector = SelectPercentile(percentile=selected_percentile)\n",
    "selector.fit_transform(X_TRAIN, Y_TRAIN)\n",
    "X_VAL = selector.transform(X_VALIDATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LinearSVC(random_state = 2, verbose = 1, C = 0.1)\n",
    "clf.fit(TRAIN_SPECIFIC[5][1], Y_TRAIN)\n",
    "predictions = clf.predict(X_VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classifaction_report_csv(report):\n",
    "    report_data = []\n",
    "    lines = report.encode('ascii', 'ignore').split('\\n')\n",
    "    for line in (lines[2:-3] + [lines[-2]]):\n",
    "        row = {}\n",
    "        row_data = line.strip().split('  ')\n",
    "        row_data = [x for x in row_data if x != '']\n",
    "        row['class'] = row_data[0]\n",
    "        row['precision'] = row_data[1]\n",
    "        row['recall'] = row_data[2]\n",
    "        row['f1_score'] = row_data[3]\n",
    "        row['support'] = row_data[4]\n",
    "        report_data.append(row)\n",
    "    dataframe = pd.DataFrame.from_dict(report_data)\n",
    "    return dataframe\n",
    "\n",
    "report = classification_report(Y_VALIDATE, predictions)\n",
    "df = classifaction_report_csv(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'micro recall score: ',recall_score(Y_VALIDATE, predictions, average = 'micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Reliable Recall Macro Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "report_data = []\n",
    "lines = report.encode('ascii', 'ignore').split('\\n')\n",
    "for line in (lines[2:-3] + [lines[-2]]):\n",
    "    row = {}\n",
    "    row_data = line.strip().split('  ')\n",
    "    row_data = [x for x in row_data if x != '']\n",
    "    row['class'] = row_data[0]\n",
    "    row['precision'] = row_data[1]\n",
    "    row['recall'] = row_data[2]\n",
    "    row['f1_score'] = row_data[3]\n",
    "    row['support'] = row_data[4]\n",
    "    report_data.append(row)\n",
    "    \n",
    "recall = []\n",
    "for d in report_data:\n",
    "    if d['support'].strip() != '0':\n",
    "        recall.append(d['recall'])\n",
    "        \n",
    "n_recall = [float(x) for x in recall]\n",
    "print 'macro recall score: ',sum(n_recall) / len(recall)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {
    "2b8ca9d25322479e9249ae4d7e76c821": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "2eb2ad99b4f2437e9353e8f3a28c333a": {
     "views": [
      {
       "cell_index": 3
      }
     ]
    },
    "384c799aa52941f3a39208684e132ba3": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "4bc9cff31be54b919e82e9b00e94d36f": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    },
    "6f01526bb61e4c389f57620300960d37": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "8ae0cabc566f48c7a870461995f444be": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "a6341dfb71f949528d1b19e3a2ed67b7": {
     "views": [
      {
       "cell_index": 11
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
